{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from prompt import STORY_HIGHLIGHTS_GENERATOR, STORY_SUBPARTS_GENERATOR, STORY_SUBPARTS_DESCRIPTION_GENERATOR\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from pathvalidate import sanitize_filepath\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTokens(base, new):\n",
    "    base['completion_tokens'] += new[\"completion_tokens\"]\n",
    "    base[\"prompt_tokens\"] += new[\"prompt_tokens\"]\n",
    "    base[\"total_tokens\"] += new[\"total_tokens\"]\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Highlights(BaseModel):\n",
    "    parts: list[str]\n",
    "    summary: str\n",
    "\n",
    "def highlights_generator(title, n):\n",
    "    \n",
    "    _input = f\"\"\"STORY TITLE: {title}\\n\\nN: {n}\"\"\"\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": STORY_HIGHLIGHTS_GENERATOR},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": _input\n",
    "            }\n",
    "        ],\n",
    "        response_format=Highlights,\n",
    "        temperature=1\n",
    "    ).to_dict()\n",
    "\n",
    "    out = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    # print(out)\n",
    "    highlights = json.loads(out)\n",
    "    usage = completion[\"usage\"]\n",
    "\n",
    "    return highlights, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlights, usage = highlights_generator()\n",
    "\n",
    "# print(highlights)\n",
    "# print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Subparts(BaseModel):\n",
    "    subparts: list[str]\n",
    "    summary: str\n",
    "\n",
    "def subparts_generator(title, story_summary, assigned_part, sub_n):\n",
    "    \n",
    "    _input = f\"\"\"STORY TITLE: {title}\\n\\nSTORY_SUMMARY: {story_summary}\\n\\nASSIGNED_PART: {assigned_part}\\n\\nN: {sub_n}\"\"\"\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": STORY_SUBPARTS_GENERATOR},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": _input\n",
    "            }\n",
    "        ],\n",
    "        response_format=Subparts,\n",
    "        temperature=1\n",
    "    ).to_dict()\n",
    "\n",
    "    out = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    # print(out)\n",
    "    subparts = json.loads(out)\n",
    "    usage = completion[\"usage\"]\n",
    "\n",
    "    return subparts, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubpartsDescription(BaseModel):\n",
    "    description: str\n",
    "\n",
    "def subparts_description_generator(story_summary, part_summary, assigned_subpart):\n",
    "    \n",
    "    _input = f\"\"\"STORY_SUMMARY: {story_summary}\\n\\nPART_SUMMARY: {part_summary}\\n\\nASSIGNED_SUBPART: {assigned_subpart}\"\"\"\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": STORY_SUBPARTS_DESCRIPTION_GENERATOR},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": _input\n",
    "            }\n",
    "        ],\n",
    "        response_format=SubpartsDescription,\n",
    "        temperature=1\n",
    "    ).to_dict()\n",
    "\n",
    "    out = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    # print(out)\n",
    "    description = json.loads(out)\n",
    "    usage = completion[\"usage\"]\n",
    "\n",
    "    return description, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def story_generator(title, n, sub_n):\n",
    "\n",
    "    print(f\"TITLE: {title}\\nPART COUNT: {n}\\nSUBPARTS_COUNT: {sub_n}\\n\\n\")\n",
    "\n",
    "    token_usage = {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}\n",
    "    \n",
    "    story_path = sanitize_filepath(f\"stories/{title.replace(' ', '_')}__{n}_{sub_n}.json\")\n",
    "    txt_path = story_path.replace(\".json\", \".txt\")\n",
    "    \n",
    "    story_dict = {\"title\": title, \"parts\": {}}\n",
    "\n",
    "    highlights, usage = highlights_generator(title=title, n=n)\n",
    "    token_usage = addTokens(token_usage, usage)\n",
    "    print(f\"GENERATED HIGHLIGHTS OF THE STORY. TOKEN USAGE: {token_usage}\")\n",
    "    story_summary = highlights[\"summary\"]\n",
    "    story_dict[\"parts\"] = {f\"part{i+1}\": {\"part_title\": part, \"subparts\": {}} for i, part in enumerate(highlights[\"parts\"])}\n",
    "    \n",
    "    with open(story_path, \"w\") as outfile:\n",
    "        json.dump(story_dict, outfile)\n",
    "\n",
    "    for part, part_gist in story_dict[\"parts\"].items():\n",
    "        subparts, usage = subparts_generator(title=title, story_summary=story_summary, assigned_part=part_gist, sub_n=sub_n)\n",
    "        token_usage = addTokens(token_usage, usage)\n",
    "        part_summary = subparts[\"summary\"]\n",
    "        story_dict[\"parts\"][part][\"subparts\"] = {f\"subpart{i+1}\": {\"subpart_title\": subpart, \"description\": \"\"} for i, subpart in enumerate(subparts[\"subparts\"])}\n",
    "        with open(story_path, \"w\") as outfile: \n",
    "            json.dump(story_dict, outfile)\n",
    "        \n",
    "        print(f\"GENERATED SUBPARTS FOR {part}. TOKEN USAGE: {token_usage}\")\n",
    "\n",
    "        for subpart, subpart_gist in story_dict[\"parts\"][part][\"subparts\"].items():\n",
    "            description, usage = subparts_description_generator(story_summary=story_summary, part_summary=part_summary, assigned_subpart=subpart_gist)\n",
    "            token_usage = addTokens(token_usage, usage)\n",
    "            story_dict[\"parts\"][part][\"subparts\"][subpart][\"description\"] = description[\"description\"]\n",
    "            with open(story_path, \"w\") as outfile:\n",
    "                json.dump(story_dict, outfile)\n",
    "\n",
    "            with open(txt_path, 'a') as f:\n",
    "                f.write(\"\\n\" + description[\"description\"])\n",
    "            \n",
    "            print(f\"GENERATED SUBPART DESCRIPTION FOR {subpart}. TOKEN USAGE: {token_usage}\")\n",
    "\n",
    "    print(f\"COMPLETED STORY. TOKEN USAGE: {token_usage}\")\n",
    "    story_dict[\"token_usage\"] = token_usage\n",
    "    with open(story_path, \"w\") as outfile:\n",
    "        json.dump(story_dict, outfile)\n",
    "\n",
    "    print(f\"STORY SAVED AT {story_path}\")\n",
    "    \n",
    "    return story_dict, token_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_stories_generator(titles, n, sub_n):\n",
    "\n",
    "    # titles - list of string titles for stories, only alphanumeric names\n",
    "    # n - number of parts for each story\n",
    "    # sub_n - number of subparts for each part\n",
    "\n",
    "    # NOTE: Each subpart adds almost 500 words in the story.\n",
    "\n",
    "    for title in titles:\n",
    "        assert len(title) > 0, (\"Story titles must have at least one character\")\n",
    "        assert title.isalnum(), (\"Story titles can only contain alphabetic or numeric values\")\n",
    "        assert len(title) <= 100, (\"Story titles can only have less than 100 chars\")\n",
    "        \n",
    "        story_generator(title, n, sub_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: F\n",
      "PART COUNT: 1\n",
      "SUBPARTS_COUNT: 1\n",
      "\n",
      "\n",
      "GENERATED HIGHLIGHTS OF THE STORY. TOKEN USAGE: {'completion_tokens': 156, 'prompt_tokens': 203, 'total_tokens': 359}\n",
      "GENERATED SUBPARTS FOR part1. TOKEN USAGE: {'completion_tokens': 312, 'prompt_tokens': 613, 'total_tokens': 925}\n",
      "GENERATED SUBPART DESCRIPTION FOR subpart1. TOKEN USAGE: {'completion_tokens': 1028, 'prompt_tokens': 1104, 'total_tokens': 2132}\n",
      "COMPLETED STORY. TOKEN USAGE: {'completion_tokens': 1028, 'prompt_tokens': 1104, 'total_tokens': 2132}\n",
      "STORY SAVED AT stories/F__1_1.json\n"
     ]
    }
   ],
   "source": [
    "titles = [\"F\"]\n",
    "n = 1\n",
    "sub_n = 1\n",
    "\n",
    "multiple_stories_generator(titles, n, sub_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
