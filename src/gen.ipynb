{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from prompt import STORY_HIGHLIGHTS_GENERATOR, STORY_SUBPARTS_GENERATOR, STORY_SUBPARTS_DESCRIPTION_GENERATOR\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTokens(base, new):\n",
    "    base['completion_tokens'] += new[\"completion_tokens\"]\n",
    "    base[\"prompt_tokens\"] += new[\"prompt_tokens\"]\n",
    "    base[\"total_tokens\"] += new[\"total_tokens\"]\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Highlights(BaseModel):\n",
    "    parts: list[str]\n",
    "    summary: str\n",
    "\n",
    "def highlights_generator(title=\"Indian Medieval History\", n=5):\n",
    "    \n",
    "    _input = f\"\"\"STORY TITLE: {title}\\n\\nN: {n}\"\"\"\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": STORY_HIGHLIGHTS_GENERATOR},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": _input\n",
    "            }\n",
    "        ],\n",
    "        response_format=Highlights,\n",
    "        temperature=1\n",
    "    ).to_dict()\n",
    "\n",
    "\n",
    "    out = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    # print(out)\n",
    "    highlights = json.loads(out)\n",
    "    usage = completion[\"usage\"]\n",
    "\n",
    "    return highlights, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlights, usage = highlights_generator()\n",
    "\n",
    "# print(highlights)\n",
    "# print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Subparts(BaseModel):\n",
    "    subparts: list[str]\n",
    "    summary: str\n",
    "\n",
    "def subparts_generator(title=\"The intro\", story_summary=\"\", assigned_part=\"\", sub_n=5):\n",
    "    \n",
    "    _input = f\"\"\"STORY TITLE: {title}\\n\\nSTORY_SUMMARY: {story_summary}\\n\\nASSIGNED_PART: {assigned_part}\\n\\nN: {sub_n}\"\"\"\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": STORY_SUBPARTS_GENERATOR},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": _input\n",
    "            }\n",
    "        ],\n",
    "        response_format=Subparts,\n",
    "        temperature=1\n",
    "    ).to_dict()\n",
    "\n",
    "\n",
    "    out = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    # print(out)\n",
    "    subparts = json.loads(out)\n",
    "    usage = completion[\"usage\"]\n",
    "\n",
    "    return subparts, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubpartsDescription(BaseModel):\n",
    "    description: str\n",
    "\n",
    "def subparts_description_generator(story_summary=\"\", part_summary=\"\", assigned_subpart=\"\"):\n",
    "    \n",
    "    _input = f\"\"\"STORY_SUMMARY: {story_summary}\\n\\nPART_SUMMARY: {part_summary}\\n\\nASSIGNED_SUBPART: {assigned_subpart}\"\"\"\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": STORY_SUBPARTS_DESCRIPTION_GENERATOR},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": _input\n",
    "            }\n",
    "        ],\n",
    "        response_format=SubpartsDescription,\n",
    "        temperature=1\n",
    "    ).to_dict()\n",
    "\n",
    "\n",
    "    out = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    # print(out)\n",
    "    description = json.loads(out)\n",
    "    usage = completion[\"usage\"]\n",
    "\n",
    "    return description, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def story_generator(title=\"\", n=1, sub_n=1):\n",
    "\n",
    "    print(f\"TITLE: {title}\\nPART COUNT: {n}\\nSUBPARTS_COUNT: {sub_n}\\n\\n\")\n",
    "\n",
    "    token_usage = {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}\n",
    "    \n",
    "    story_path = f\"{title.replace(\" \", \"_\")}__{n}_{sub_n}.json\"\n",
    "    txt_path = story_path.replace(\".json\", \".txt\")\n",
    "    \n",
    "    story_dict = {\"title\": title, \"parts\": {}}\n",
    "\n",
    "    highlights, usage = highlights_generator(title=title, n=n)\n",
    "    token_usage = addTokens(token_usage, usage)\n",
    "    print(f\"GENERATED HIGHLIGHTS OF THE STORY. TOKEN USAGE: {token_usage}\")\n",
    "    story_summary = highlights[\"summary\"]\n",
    "    story_dict[\"parts\"] = {f\"part{i+1}\": {\"part_title\": part, \"subparts\": {}} for i, part in enumerate(highlights[\"parts\"])}\n",
    "    \n",
    "    with open(story_path, \"w\") as outfile:\n",
    "        json.dump(story_dict, outfile)\n",
    "\n",
    "    for part, part_gist in story_dict[\"parts\"].items():\n",
    "        subparts, usage = subparts_generator(title=title, story_summary=story_summary, assigned_part=part_gist, sub_n=sub_n)\n",
    "        token_usage = addTokens(token_usage, usage)\n",
    "        part_summary = subparts[\"summary\"]\n",
    "        story_dict[\"parts\"][part][\"subparts\"] = {f\"subpart{i+1}\": {\"subpart_title\": subpart, \"description\": \"\"} for i, subpart in enumerate(subparts[\"subparts\"])}\n",
    "        with open(story_path, \"w\") as outfile: \n",
    "            json.dump(story_dict, outfile)\n",
    "        \n",
    "        print(f\"GENERATED SUBPARTS FOR {part}. TOKEN USAGE: {token_usage}\")\n",
    "\n",
    "        for subpart, subpart_gist in story_dict[\"parts\"][part][\"subparts\"].items():\n",
    "            description, usage = subparts_description_generator(story_summary=story_summary, part_summary=part_summary, assigned_subpart=subpart_gist)\n",
    "            token_usage = addTokens(token_usage, usage)\n",
    "            story_dict[\"parts\"][part][\"subparts\"][subpart][\"description\"] = description[\"description\"]\n",
    "            with open(story_path, \"w\") as outfile:\n",
    "                json.dump(story_dict, outfile)\n",
    "\n",
    "            with open(txt_path, 'a') as f:\n",
    "                f.write(description[\"description\"])\n",
    "            \n",
    "            print(f\"GENERATED SUBPART DESCRIPTION FOR {subpart}. TOKEN USAGE: {token_usage}\")\n",
    "\n",
    "    print(f\"COMPLETED STORY. TOKEN USAGE: {token_usage}\")\n",
    "    story_dict[\"token_usage\"] = token_usage\n",
    "    with open(story_path, \"w\") as outfile:\n",
    "        json.dump(story_dict, outfile)\n",
    "\n",
    "    print(f\"SAVED STORY AT {story_path}\")\n",
    "    \n",
    "    return story_dict, token_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Story of King Md. Husaid From Lahore\n",
      "PART COUNT: 5\n",
      "SUBPARTS_COUNT: 5\n",
      "\n",
      "\n",
      "GENRATED HIGHLIGHTS OF THE STORY\n",
      "GENRATED SUBPARTS FOR part1\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart1\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart2\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart3\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart4\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart5\n",
      "GENRATED SUBPARTS FOR part2\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart1\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart2\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart3\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart4\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart5\n",
      "GENRATED SUBPARTS FOR part3\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart1\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart2\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart3\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart4\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart5\n",
      "GENRATED SUBPARTS FOR part4\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart1\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart2\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart3\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart4\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart5\n",
      "GENRATED SUBPARTS FOR part5\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart1\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart2\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart3\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart4\n",
      "GENRATED SUBPART DESCRIPTION FOR subpart5\n",
      "COMPLETE STORY\n",
      "SAVED STORY AT Story of King Md. Husaid From Lahore_5_5.json\n"
     ]
    }
   ],
   "source": [
    "story, usage = story_generator(title=\"Story of King Md. Husaid From Lahore\", n=5, sub_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = 'story.txt'\n",
    "\n",
    "with open(txt_path, 'a') as f:\n",
    "    for p, pg in story[\"parts\"].items():\n",
    "        for s, sg in pg[\"subparts\"].items():\n",
    "            description = sg[\"description\"][\"description\"]\n",
    "            f.write(description)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
